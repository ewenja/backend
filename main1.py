from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
import tempfile, os, ffmpeg
from transformers import pipeline
from opencc import OpenCC

app = FastAPI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å»¶é²åˆå§‹åŒ– ASR
asr = None

@app.on_event("startup")
async def startup_event():
    print("ğŸš€ Server started, waiting for first ASR request...")

@app.post("/upload")
async def upload_video(
    file: UploadFile = File(...),
    lang: str = Form("traditional")
):
    global asr
    if asr is None:
        print("â³ Loading Whisper model...")
        asr = pipeline("automatic-speech-recognition", model="openai/whisper-small", device=-1)

    # æš«å­˜æª”æ¡ˆ
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp:
        temp.write(await file.read())
        temp_path = temp.name

    # æŠ½éŸ³è¨Š
    audio_path = temp_path.replace(".mp4", ".mp3")
    ffmpeg.input(temp_path).output(audio_path).run()

    # Whisper èªéŸ³è½‰æ–‡å­—
    result = asr(audio_path)
    transcript = result["text"]

    # ç¹é«” / ç°¡é«”è½‰æ›
    cc = OpenCC("t2s") if lang == "simplified" else OpenCC("s2t")
    transcript = cc.convert(transcript)

    # æ¨¡æ“¬ GPT æ‘˜è¦
    summary = "ã€".join(transcript.split("ã€‚")[:5]) + "ã€‚"

    # æ¸…ç†æš«å­˜æª”
    os.remove(temp_path)
    os.remove(audio_path)

    return {
        "transcript": transcript,
        "summary": summary,
        "lang": lang
    }
